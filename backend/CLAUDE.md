
## üöÄ –í–ê–ñ–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ (—Å–æ—Ö—Ä–∞–Ω–∏ —Å–µ–±–µ –≤—Ä–µ–º—è!)

### –ü—Ä–æ–±–ª–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤–æ–∑–Ω–∏–∫–∞—é—Ç:
- API –∫–ª—é—á –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∏–∑ .env —Ñ–∞–π–ª–∞
- –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –±–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
- uv –Ω–µ –ø–µ—Ä–µ–¥–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ

### –†–ï–®–ï–ù–ò–ï:
1. **–£–±–µ–¥–∏—Å—å —á—Ç–æ –≤ main.py –µ—Å—Ç—å load_dotenv():**
   ```python
   from dotenv import load_dotenv
   load_dotenv()  # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞
   ```

2. **–ó–∞–ø—É—Å–∫–∞–π —Å–µ—Ä–≤–µ—Ä –¢–û–õ–¨–ö–û –¢–ê–ö:**
   ```bash
   cd backend && uv run uvicorn src.api.main:app --reload --port 8000
   ```

3. **–ü—Ä–æ–≤–µ—Ä—å —á—Ç–æ API –∫–ª—é—á –∑–∞–≥—Ä—É–∂–µ–Ω:**
   ```bash
   curl -s http://localhost:8000/health | grep openai_configured
   # –î–æ–ª–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å: "openai_configured":true
   ```

## üìù –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ API

### –§–æ—Ä–º–∞—Ç –∑–∞–ø—Ä–æ—Å–∞:
```bash
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{"query": "–¢–ï–ö–°–¢ –ó–ê–ü–†–û–°–ê –ù–ê –†–£–°–°–ö–û–ú"}' \
  -o /tmp/result.json
```

### –í–ê–ñ–ù–û:
- Endpoint: `/api/v1/query` (–ù–ï /api/query, –ù–ï /query)
- –ü–æ–ª–µ: `query` (–ù–ï question, –ù–ï text)
- Content-Type –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω
- –†–µ–∑—É–ª—å—Ç–∞—Ç –≤ SSE —Ñ–æ—Ä–º–∞—Ç–µ (Server-Sent Events)

### –ü—Ä–∏–º–µ—Ä –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞:
```bash
# –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{"query": "–ß—Ç–æ –∞–≤—Ç–æ—Ä –ø–∏—à–µ—Ç –ø—Ä–æ AI –∞–≥–µ–Ω—Ç–æ–≤?"}' \
  -o /tmp/test.json

# –ü–æ–¥–æ–∂–¥–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É (30-40 —Å–µ–∫)
sleep 35

# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
tail -5 /tmp/test.json | grep main_sources
```

## Language Enforcement System

### Purpose
Multi-lingual support system that detects query language and enforces consistent response language across all LLM calls.

### Key Components
- `utils/language_utils.py:10-60` - Language detection engine
- `utils/language_utils.py:62-104` - Language instruction generation
- `utils/language_utils.py:107-172` - Prompt preparation utilities

### Integration Points
The language system is integrated into all core LLM services:
- **Map Service** (`services/map_service.py:18`) - Uses `prepare_system_message_with_language()` for language enforcement
- **Reduce Service** (`services/reduce_service.py:15`) - Uses `prepare_system_message_with_language()`
- **Comment Group Map Service** (`services/comment_group_map_service.py:22`) - Uses `prepare_prompt_with_language_instruction()`
- **Comment Synthesis Service** (`services/comment_synthesis_service.py:13`) - Uses both system message and prompt preparation functions

### Language Detection Logic
- Analyzes character patterns (ASCII vs Cyrillic)
- Counts words for more accurate detection
- Defaults to Russian for ambiguous cases
- Enforces response language regardless of source content language

### Usage Pattern
```python
from ..utils.language_utils import prepare_prompt_with_language_instruction, prepare_system_message_with_language

# Method 1: System message override (preferred for LLMs)
system_message = prepare_system_message_with_language(base_system, query)

# Method 2: Prompt prepending (fallback method)
enhanced_prompt = prepare_prompt_with_language_instruction(prompt_template, query)
```

## ‚ö†Ô∏è –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏:
- ‚ùå source .env && uv run... - –ù–ï –†–ê–ë–û–¢–ê–ï–¢
- ‚ùå export $(cat .env) && uv run... - –ù–ï –†–ê–ë–û–¢–ê–ï–¢
- ‚ùå uv run --env-file .env... - –ù–ï –†–ê–ë–û–¢–ê–ï–¢
- ‚úÖ load_dotenv() –≤ main.py - –†–ê–ë–û–¢–ê–ï–¢!


"""Reddit Synthesis Service - Gemini-powered analysis of Reddit content.

This module provides synthesis of Reddit search results using Google Gemini AI
to extract insights, sentiment, and actionable information from community discussions.
"""

import logging
from typing import Optional, List, Dict, Any

from .. import config
from ..utils.language_utils import detect_query_language
from .reddit_service import RedditSearchResult, RedditSource
from .google_ai_studio_client import create_google_ai_studio_client, GoogleAIStudioError

logger = logging.getLogger(__name__)

DEFAULT_SYNTHESIS_MODEL = "gemini-2.0-flash"


class RedditSynthesisService:
    """Service for synthesizing Reddit content via Gemini AI.
    
    Analyzes Reddit posts and extracts:
    - Reality Check: Bugs, edge cases, hardware issues
    - Hacks: Workarounds and unofficial solutions
    - Vibe: Overall sentiment and community opinion
    """
    
    def __init__(self, model: Optional[str] = None):
        """Initialize synthesis service.
        
        Args:
            model: Gemini model to use (default: gemini-2.0-flash)
        """
        # FIX: Use MODEL_SYNTHESIS (gemini-3-flash-preview) for high-quality Reddit analysis
        # This matches the main synthesis model for expert responses
        self.model = model or config.MODEL_SYNTHESIS or DEFAULT_SYNTHESIS_MODEL
        self._client = create_google_ai_studio_client()
    
    async def synthesize(
        self,
        query: str,
        reddit_result: Any, # Typed as Any to support both result types
        max_sources_in_context: int = 10
    ) -> str:
        """Synthesize Reddit insights via Gemini.
        
        Args:
            query: Original user query
            reddit_result: Result from Reddit search
            max_sources_in_context: Max number of sources to include in prompt
        
        Returns:
            Markdown-formatted synthesis with insights (in query language)
        """
        # Unified check for empty results
        has_posts = False
        if hasattr(reddit_result, 'posts') and reddit_result.posts:
            has_posts = True
        elif hasattr(reddit_result, 'sources') and reddit_result.sources:
            has_posts = True
            
        if not has_posts:
            query_lang = detect_query_language(query)
            if query_lang == "Russian":
                return "ÐžÐ±ÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ðµ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°."
            return "No community discussions found for this query."
        
        # Detect query language for response
        query_language = detect_query_language(query)
        
        # Build context from sources
        context = self._build_context(reddit_result, max_sources_in_context)
        
        # Create synthesis prompt in query language
        messages = self._create_synthesis_prompt(query, context, query_language)
        
        try:
            response = await self._client.chat_completions_create(
                model=self.model,
                messages=messages,
                temperature=0.3  # Lower temp for factual analysis
            )
            
            synthesis = response.choices[0].message.content.strip()
            
            # Unified access for logging
            if hasattr(reddit_result, 'posts'):
                count = reddit_result.total_found
            else:
                count = reddit_result.found_count
                
            logger.info(
                f"Reddit synthesis completed for query: {query[:50]}... "
                f"(found {count} posts)"
            )
            
            return synthesis
            
        except GoogleAIStudioError as e:
            logger.error(f"Gemini synthesis failed: {e}")
            # Fallback: return raw markdown if synthesis fails
            return self._create_fallback_response(reddit_result, query_language)
        except Exception as e:
            logger.error(f"Unexpected error in synthesis: {e}")
            return self._create_fallback_response(reddit_result, query_language)
    
    # High-signal keywords indicating the OP found the solution helpful
    VERIFICATION_KEYWORDS = {
        "worked", "thanks", "thank you", "solved", "fixed", 
        "ÑÑ€Ð°Ð±Ð¾Ñ‚Ð°Ð»Ð¾", "ÑÐ¿Ð°ÑÐ¸Ð±Ð¾", "Ñ€ÐµÑˆÐ¸Ð»"
    }

    def _format_comments_recursive(self, comments: List[Dict[str, Any]], depth: int = 0, max_depth: int = 3, post_author: str = None) -> str:
        """Recursively format comments tree.
        
        Args:
            comments: List of comment dictionaries
            depth: Current nesting depth
            max_depth: Maximum recursion depth
            post_author: Username of the post author (OP) to detect verified solutions
        """
        if depth > max_depth or not comments:
            return ""
        
        output = []
        indent = "  " * (depth + 1)
        
        for i, comment in enumerate(comments, 1):
            # Handle different comment structures
            if isinstance(comment, dict):
                author = comment.get('author', 'unknown')
                body = comment.get('body', '') or comment.get('text', '')
                score = comment.get('score', 0)
                replies = comment.get('replies', [])
            else:
                # Fallback for objects
                author = getattr(comment, 'author', 'unknown')
                body = getattr(comment, 'body', '') or getattr(comment, 'text', '')
                score = getattr(comment, 'score', 0)
                replies = getattr(comment, 'replies', [])

            if body:
                # Detect OP Verification (Golden Answer)
                # If the OP replied to this comment saying "thanks", "solved", "worked", etc.
                is_verified = False
                if post_author and post_author != "unknown" and replies:
                    for reply in replies:
                        # Check reply author safely
                        r_author = reply.get('author') if isinstance(reply, dict) else getattr(reply, 'author', '')
                        r_body = (reply.get('body') if isinstance(reply, dict) else getattr(reply, 'body', '')) or ""
                        
                        if r_author == post_author and any(kw in r_body.lower() for kw in self.VERIFICATION_KEYWORDS):
                            is_verified = True
                            break

                # Truncate extremely long comments but keep enough for context (2000 chars)
                if len(body) > 2000:
                    body = body[:2000] + "... (truncated)"
                
                # Add visual marker for LLM
                verified_tag = "[âœ… OP VERIFIED SOLUTION] " if is_verified else ""
                
                prefix = "â””â”€ " if depth > 0 else f"{i}. "
                header = f"{indent}{prefix}{verified_tag}[{author} | {score}]: "
                
                # Handle multi-line content (code blocks, paragraphs) by indenting subsequent lines
                # This preserves structure for the LLM
                content_indent = "\n" + indent + ("   " if depth > 0 else "   ")
                formatted_body = body.replace("\n", content_indent)
                
                output.append(f"{header}{formatted_body}")
                
                # Process replies if they exist and we haven't hit max depth
                if replies:
                    replies_text = self._format_comments_recursive(replies, depth + 1, max_depth, post_author=post_author)
                    if replies_text:
                        output.append(replies_text)
        
        return "\n".join(output)

    def _build_context(
        self,
        reddit_result: Any, # Typed as Any to support both result types during migration
        max_sources: int
    ) -> str:
        """Build context string from Reddit sources.
        
        Args:
            reddit_result: Reddit search result (EnhancedSearchResult or RedditSearchResult)
            max_sources: Maximum sources to include
        
        Returns:
            Formatted context string
        """
        # Handle both result types
        if hasattr(reddit_result, 'posts'):
            sources = reddit_result.posts[:max_sources]
        else:
            sources = reddit_result.sources[:max_sources]
        
        # DEBUG: Log sources content
        logger.info(f"SYNTHESIS DEBUG: Building context from {len(sources)} sources")
        
        context_parts = []
        for i, src in enumerate(sources, 1):
            # Handle different content attributes (selftext vs content)
            raw_content = getattr(src, 'selftext', '') or getattr(src, 'content', '') or "[No content available]"
            
            # Increase limit to 15,000 chars to leverage Gemini's context window
            content_preview = raw_content[:15000]
            if len(raw_content) > 15000:
                content_preview += "... (truncated)"
            
            # Format top comments with tree structure
            comments_section = ""
            # Handle comments attribute (top_comments vs comments)
            comments_data = getattr(src, 'top_comments', []) or getattr(src, 'comments', [])
            
            if comments_data:
                # Pass post author to recursive formatter for OP verification detection
                post_author = getattr(src, 'author', 'unknown')
                comments_text = self._format_comments_recursive(comments_data, post_author=post_author)
                if comments_text:
                    comments_section = f"\n   - **Discussion Tree:**\n{comments_text}"
            
            context_parts.append(
                f"{i}. **{src.title}** (r/{src.subreddit})\n"
                f"   - Content: {content_preview}\n"
                # Use getattr for stats to be safe
                f"   - Stats: Score: {getattr(src, 'score', 0)} | Comments: {getattr(src, 'num_comments', getattr(src, 'comments_count', 0))}\n"
                f"   - URL: {src.url}"
                f"{comments_section}"
            )
        
        return "\n\n".join(context_parts)
    
    def _create_synthesis_prompt(
        self,
        query: str,
        context: str,
        query_language: str = "English"
    ) -> List[Dict[str, str]]:
        """Create synthesis prompt for Gemini.
        
        Args:
            query: User query
            context: Reddit posts context
            query_language: Language of the query (English or Russian)
        
        Returns:
            Messages list for chat completion
        """
        # Determine response language
        is_russian = query_language == "Russian"
        
        # Get current date for context (Project is in 2026)
        from datetime import datetime
        current_date_str = datetime.now().strftime("%Y-%m-%d")
        
        if is_russian:
            system_prompt = f"""Ð’Ñ‹ â€” Ð’ÐµÐ´ÑƒÑ‰Ð¸Ð¹ Ð˜Ð½Ð¶ÐµÐ½ÐµÑ€ (Staff Engineer), Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽÑ‰Ð¸Ð¹ Ð±Ð°Ð·Ñƒ Ð·Ð½Ð°Ð½Ð¸Ð¹ Reddit Ð´Ð»Ñ ÐºÐ¾Ð»Ð»ÐµÐ³Ð¸.
Ð¡Ð•Ð“ÐžÐ”ÐÐ¯: {current_date_str}. Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ð¹Ñ‚Ðµ, Ñ‡Ñ‚Ð¾ Ð¼Ñ‹ Ð² 2026 Ð³Ð¾Ð´Ñƒ.

Ð’Ð°ÑˆÐ° Ð·Ð°Ð´Ð°Ñ‡Ð° â€” ÑÐ¸Ð½Ñ‚ÐµÐ·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¸ÑÑ‡ÐµÑ€Ð¿Ñ‹Ð²Ð°ÑŽÑ‰Ð¸Ð¹ Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ñ… Ñ‚Ñ€ÐµÐ´Ð¾Ð² (Ð¿Ð¾ÑÑ‚ + Ð´ÐµÑ€ÐµÐ²Ð¾ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ²).

Ð’Ð¥ÐžÐ”ÐÐ«Ð• Ð”ÐÐÐÐ«Ð•:
- Ð’Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ.
- Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ñ‚Ñ€ÐµÐ´Ñ‹ Ñ Reddit (Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ Ð²Ð»Ð¾Ð¶ÐµÐ½Ð½Ñ‹Ðµ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸).

ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð™ ÐÐÐÐ›Ð˜Ð— (Ð’ÐÐ–ÐÐž):
- FACT-MAXING: Ð˜Ð³Ð½Ð¾Ñ€Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ ÑÐ¼Ð¾Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑˆÑƒÐ¼. Ð˜Ñ‰Ð¸Ñ‚Ðµ Ñ†Ð¸Ñ„Ñ€Ñ‹, Ð±ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¸, Ð²ÐµÑ€ÑÐ¸Ð¸ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐº, Ð»Ð¾Ð³Ð¸.
- LINK PRIORITY: Ð•ÑÐ»Ð¸ Ð¿Ð¾ÑÑ‚ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ ÑÑÑ‹Ð»ÐºÑƒ Ð½Ð° GitHub/HuggingFace, Ð²Ñ‹Ð´ÐµÐ»Ð¸Ñ‚Ðµ ÐµÑ‘ ÐºÐ°Ðº **[PRIMARY SOURCE]**.
- CODE VERIFICATION: Ð•ÑÐ»Ð¸ Ð² ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÑÑ… Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶Ð¸Ð»Ð¸ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ ÐºÐ¾Ð´Ð° â€” Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð˜Ð¡ÐŸÐ ÐÐ’Ð›Ð•ÐÐÐ£Ð® Ð²ÐµÑ€ÑÐ¸ÑŽ.
- PIVOT ALERT: Ð•ÑÐ»Ð¸ ÑÐ¾Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð¾ Ð Ð•Ð—ÐšÐž Ð½Ðµ Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¸Ð· Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð¸ ÑÐ¾Ð²ÐµÑ‚ÑƒÐµÑ‚ Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ñƒ â€” Ð½Ð°Ñ‡Ð½Ð¸Ñ‚Ðµ Ð¾Ñ‚Ð²ÐµÑ‚ Ñ Ð±Ð»Ð¾ÐºÐ° `ðŸš¨ **Ð¡ÐœÐ•ÐÐ Ð¢Ð Ð•ÐÐ”Ð (COMMUNITY PIVOT)**` Ð¸ Ð¾Ð±ÑŠÑÑÐ½Ð¸Ñ‚Ðµ Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ.
- COMPARISON TABLES: Ð•ÑÐ»Ð¸ ÑÑ€Ð°Ð²Ð½Ð¸Ð²Ð°ÑŽÑ‚ÑÑ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² â€” Ð’Ð« ÐžÐ‘Ð¯Ð—ÐÐÐ« ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ Markdown-Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ (ÐšÑ€Ð¸Ñ‚ÐµÑ€Ð¸Ð¸ vs Ð˜Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹) Ñ Ð²ÐµÑ€Ð´Ð¸ÐºÑ‚Ð¾Ð¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ð°.

Ð¡Ð¢Ð Ð£ÐšÐ¢Ð£Ð Ð ÐžÐ¢Ð’Ð•Ð¢Ð (ÐŸÐµÑ€ÐµÐ²ÐµÑ€Ð½ÑƒÑ‚Ð°Ñ Ð¿Ð¸Ñ€Ð°Ð¼Ð¸Ð´Ð°):
1. **ÐŸÑ€ÑÐ¼Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ / Ð ÐµÑˆÐµÐ½Ð¸Ðµ:** Ð¡Ñ€Ð°Ð·Ñƒ Ð´Ð°Ð¹Ñ‚Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‰ÐµÐµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¸Ð»Ð¸ ÐºÐ¾Ð½ÑÐµÐ½ÑÑƒÑ Ð½Ð° 2026 Ð³Ð¾Ð´.
2. **Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð´ÐµÑ‚Ð°Ð»Ð¸:** ÐšÐ¾Ð½Ñ„Ð¸Ð³Ð¸, Ñ„Ð»Ð°Ð³Ð¸, Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹ ÐºÐ¾Ð´Ð°. 
3. **ÐÑŽÐ°Ð½ÑÑ‹ Ð¸ Ð¡Ð¿Ð¾Ñ€Ñ‹:** Ð•ÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ñ€Ð°Ð·Ð½Ð¾Ð³Ð»Ð°ÑÐ¸Ñ, Ñ‡ÐµÑ‚ÐºÐ¾ ÑƒÐºÐ°Ð¶Ð¸Ñ‚Ðµ ÑÑ‚Ð¾.
4. **Edge Cases:** Ðž Ñ‡ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´Ð°ÑŽÑ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð¸ (Ð±Ð°Ð³Ð¸, Ð»Ð¸Ð¼Ð¸Ñ‚Ñ‹).

Ð¡Ð¢Ð˜Ð›Ð¬:
- ÐŸÑ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹, Ð¿Ð»Ð¾Ñ‚Ð½Ñ‹Ð¹, "Ð±ÐµÐ· Ð²Ð¾Ð´Ñ‹".
- Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Markdown Ð´Ð»Ñ ÐºÐ¾Ð´Ð° Ð¸ ÑÐ¿Ð¸ÑÐºÐ¾Ð².
- ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹Ñ‚Ðµ Ð¢ÐžÐ›Ð¬ÐšÐž Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ."""

            user_prompt = f"""**Ð’Ð¾Ð¿Ñ€Ð¾Ñ:** {query}

**Ð‘Ð°Ð·Ð° Ð·Ð½Ð°Ð½Ð¸Ð¹ Reddit:**

{context}

Ð”Ð°Ð¹Ñ‚Ðµ ÑÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚, Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ð½Ð° {current_date_str}."""
        else:
            system_prompt = f"""You are a Staff Engineer analyzing the Reddit knowledge base for a colleague.
TODAY IS: {current_date_str}. Keep in mind we are in 2026.

Your task is to synthesize a comprehensive technical answer based on the provided threads (post + comment trees).

INPUT:
- User Query.
- Structured Reddit threads (including nested comments).

CRITICAL ANALYSIS (IMPORTANT):
- FACT-MAXING: Ignore emotional noise. Focus on numbers, benchmarks, library versions, logs.
- LINK PRIORITY: If a post contains a link to GitHub/HF, highlight it as **[PRIMARY SOURCE]**.
- CODE VERIFICATION: If comments offer a code fix, use the CORRECTED version.
- PIVOT ALERT: If the community STRONGLY advises against the user's premise/tool and suggests an alternative, start with a `ðŸš¨ **COMMUNITY PIVOT**` block explaining why.
- COMPARISON TABLES: If multiple tools/approaches are compared, YOU MUST output a Markdown table summarizing the consensus (Criteria vs Tools).

RESPONSE STRUCTURE (Inverted Pyramid):
1. **Direct Answer / Solution:** Start immediately with the working solution or "best practice" for 2026.
2. **Technical Details:** Configs, flags, code snippets.
3. **Nuance & Debate:** If there is disagreement, state it clearly.
4. **Edge Cases:** Warnings from users (bugs, limitations).

STYLE:
- Professional, dense, no fluff.
- Use Markdown for code and lists.
- Answer in English."""

            user_prompt = f"""**Query:** {query}

**Reddit Knowledge Base:**

{context}

Provide an expert technical synthesis relevant for {current_date_str}."""

        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    
    def _create_fallback_response(
        self, 
        reddit_result: Any,
        query_language: str = "English"
    ) -> str:
        """Create fallback response when synthesis fails.
        
        Args:
            reddit_result: Reddit search result
            query_language: Language of the query
        
        Returns:
            Basic markdown response with sources
        """
        is_russian = query_language == "Russian"
        
        # Unified access
        if hasattr(reddit_result, 'posts'):
            sources = reddit_result.posts
            count = reddit_result.total_found
        else:
            sources = reddit_result.sources
            count = reddit_result.found_count
            
        if not sources:
            if is_russian:
                return "ÐžÐ±ÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ðµ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°."
            return "No community discussions found for this query."
        
        if is_russian:
            lines = ["### ÐžÐ±ÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ Ð² ÑÐ¾Ð¾Ð±Ñ‰ÐµÑÑ‚Ð²Ðµ", ""]
            lines.append(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {count} Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ñ… Ð¿Ð¾ÑÑ‚Ð¾Ð² Ð½Ð° Reddit:")
        else:
            lines = ["### Community Discussions", ""]
            lines.append(f"Found {count} relevant posts on Reddit:")
        
        lines.append("")
        
        for src in sources[:5]:
            # FIX: Escape markdown special characters to prevent injection/broken formatting
            escaped_title = src.title.replace("[", "\\[").replace("]", "\\]")
            escaped_url = src.url.replace(")", "%29")  # URL-encode closing parenthesis
            
            # Use getattr for unified access
            subreddit = getattr(src, 'subreddit', 'unknown')
            score = getattr(src, 'score', 0)
            comments = getattr(src, 'num_comments', getattr(src, 'comments_count', 0))
            
            lines.append(f"- **[{escaped_title}]({escaped_url})** (r/{subreddit})")
            if is_russian:
                lines.append(f"  Ð ÐµÐ¹Ñ‚Ð¸Ð½Ð³: {score} | ÐšÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ²: {comments}")
            else:
                lines.append(f"  Score: {score} | Comments: {comments}")
            lines.append("")
        
        return "\n".join(lines)
    
    async def quick_synthesize(
        self,
        query: str,
        reddit_result: Any
    ) -> Dict[str, Any]:
        """Quick synthesis returning structured data.
        
        Args:
            query: User query
            reddit_result: Reddit search result
        
        Returns:
            Dictionary with synthesis text and metadata
        """
        synthesis_text = await self.synthesize(query, reddit_result)
        
        # Unified access for stats
        if hasattr(reddit_result, 'posts'):
            count = len(reddit_result.posts)
            total = reddit_result.total_found
        else:
            count = len(reddit_result.sources)
            total = reddit_result.found_count
        
        return {
            "synthesis": synthesis_text,
            "sources_count": count,
            "total_found": total,
            "processing_time_ms": reddit_result.processing_time_ms,
            "model_used": self.model
        }


# Convenience function
async def synthesize_reddit_content(
    query: str,
    reddit_result: RedditSearchResult,
    model: Optional[str] = None
) -> str:
    """Convenience function to synthesize Reddit content.
    
    Args:
        query: User query
        reddit_result: Reddit search result
        model: Optional model override
    
    Returns:
        Synthesis markdown text
    """
    service = RedditSynthesisService(model)
    return await service.synthesize(query, reddit_result)

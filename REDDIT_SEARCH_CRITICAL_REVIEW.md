# ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ñ€ĞµĞ²ÑŒÑ Reddit Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ² Experts Panel

**Ğ”Ğ°Ñ‚Ğ° Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°:** 2026-02-12
**ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº:** Claude (GLM-5)
**Ğ’ĞµÑ€ÑĞ¸Ñ ĞºĞ¾Ğ´Ğ°:** main branch (fea1c25)

---

## ğŸ“‹ ĞĞ±Ñ‰Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ°: â­â­â­ (3/5)

**Ğ’ĞµÑ€Ğ´Ğ¸ĞºÑ‚:** Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ° Ğ¸ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞ¼Ğ°Ğ½Ğ°, Ğ½Ğ¾ Ğ¸Ğ¼ĞµĞµÑ‚ ÑĞµÑ€ÑŒÑ‘Ğ·Ğ½Ñ‹Ğµ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğµ Ñ€Ğ¸ÑĞºĞ¸ Ğ¸ "Ğ´Ñ‹Ñ€Ñ‹" Ğ² Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸.

---

## ğŸ“Š ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹

### ĞĞ±Ñ‰Ğ°Ñ ÑÑ…ĞµĞ¼Ğ°
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            LAYERS OF COMPLEXITY                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  L1: Frontend (React)                                                       â”‚
â”‚      â””â”€â”€ QueryForm.tsx â†’ include_reddit toggle                             â”‚
â”‚                                                                             â”‚
â”‚  L2: Backend Orchestration (simplified_query_endpoint.py)                   â”‚
â”‚      â””â”€â”€ process_reddit_pipeline() â†’ Translation â†’ Search â†’ Synthesis      â”‚
â”‚                                                                             â”‚
â”‚  L3: Enhanced Service (reddit_enhanced_service.py)                          â”‚
â”‚      â””â”€â”€ AI Scout â†’ Multi-strategy search â†’ Semantic Ranking               â”‚
â”‚                                                                             â”‚
â”‚  L4: HTTP Client (reddit_service.py)                                        â”‚
â”‚      â””â”€â”€ Circuit Breaker â†’ Retry â†’ HTTP Proxy                              â”‚
â”‚                                                                             â”‚
â”‚  L5: Proxy Service (services/reddit-proxy/src/index.ts)                     â”‚
â”‚      â””â”€â”€ MCP Watchdog â†’ Aggregator â†’ Cache                                 â”‚
â”‚                                                                             â”‚
â”‚  L6: MCP Server (reddit-mcp-buddy)                                          â”‚
â”‚      â””â”€â”€ Reddit API â†’ asyncpraw                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
| Ğ¤Ğ°Ğ¹Ğ» | Ğ¡Ñ‚Ñ€Ğ¾ĞºĞ¸ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|------|--------|------------|
| `backend/src/api/simplified_query_endpoint.py` | ~1100 | ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Reddit pipeline |
| `backend/src/services/reddit_enhanced_service.py` | 757 | Multi-strategy search, AI Scout |
| `backend/src/services/reddit_synthesis_service.py` | 445 | Gemini-powered synthesis |
| `backend/src/services/reddit_service.py` | 398 | HTTP client, Circuit Breaker |
| `services/reddit-proxy/src/index.ts` | 803 | MCP Watchdog, Aggregator |

---

## âœ… Ğ¡Ğ˜Ğ›Ğ¬ĞĞ«Ğ• Ğ¡Ğ¢ĞĞ ĞĞĞ«

### 1. ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Sidecar Pattern ğŸ—ï¸

```
Backend â†’ Reddit Proxy (Fly.io) â†’ MCP reddit-buddy â†’ Reddit API
```

**ĞŸĞ»ÑÑÑ‹:**
- âœ… Ğ˜Ğ·Ğ¾Ğ»ÑÑ†Ğ¸Ñ ÑĞ±Ğ¾ĞµĞ² â€” Reddit Ğ½Ğµ Ñ€Ğ¾Ğ½ÑĞµÑ‚ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ±ÑĞºĞµĞ½Ğ´
- âœ… IP Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ° â€” Reddit Ğ½Ğµ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒĞµÑ‚ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ÑĞµÑ€Ğ²ĞµÑ€
- âœ… ĞĞµĞ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾Ğµ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
- âœ… Watchdog pattern Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ respawn

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ:**
```typescript
// services/reddit-proxy/src/index.ts
class WatchdogMCPManager {
  private readonly maxRestarts = 10;

  async executeTool<T>(toolName: string, args: Record<string, unknown>): Promise<T> {
    // Auto-restart if not ready
    if (!this.isReady || !this.client) {
      await this.respawn();
    }
    // 15s timeout â†’ SIGKILL â†’ respawn
  }
}
```

### 2. AI Scout v2 (Gemini 3 Flash) ğŸ¤–

**Ğ˜Ğ½Ğ½Ğ¾Ğ²Ğ°Ñ†Ğ¸Ñ:** Intent-based Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ³Ğ¾ keyword matching.

```python
# backend/src/services/reddit_enhanced_service.py:209-289
async def _plan_search_strategy(self, query: str) -> Dict[str, Any]:
    prompt = f"""You are an expert Reddit OSINT Navigator.
    User Query: "{query}"

    Task: Create a precise Search Plan to find practical, technical information.
    1. Identify 3-7 relevant technical subreddits.
    2. Generate 3-5 SPECIFIC search queries to find guides, workflows, or technical details.
    3. Extract 2-3 CRITICAL keywords from the user query.

    Output JSON:
    {{
      "subreddits": ["LocalLLaMA", "ClaudeAI"],
      "queries": ["\"Claude Code\" workflow", "\"Claude Code\" setup guide"],
      "keywords": ["Skills", "CLI", "Claude"]
    }}
    """
```

**ĞŸĞ»ÑÑÑ‹:**
- âœ… ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ´Ğ±Ğ¾Ñ€ ÑÑƒĞ±Ñ€ĞµĞ´Ğ´Ğ¸Ñ‚Ğ¾Ğ²
- âœ… Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ñ… ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… ÑĞ»Ğ¾Ğ² Ğ´Ğ»Ñ semantic ranking
- âœ… Intent queries Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°

### 3. Multi-Strategy Parallel Search âš¡

**6 ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¹ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑÑ‚ÑÑ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾:**

| Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ | Query | Ğ¦ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ |
|-----------|-------|----------|
| `combined_relevance` | `(query) AND (subreddit:A OR ...)` | Ğ›ÑƒÑ‡ÑˆĞµĞµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ |
| `combined_top_year` | Same, sort=top, time=year | ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ·Ğ° Ğ³Ğ¾Ğ´ |
| `combined_new_month` | Same, sort=new, time=month | Ğ¡Ğ²ĞµĞ¶ĞµÑÑ‚ÑŒ |
| `ai_intent_N` | AI-ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ | Intent coverage |
| `high_signal_title` | `title:(query) AND title:(Guide OR ...)` | Ğ“Ğ°Ğ¹Ğ´Ñ‹/Ñ‚ÑƒÑ‚Ğ¾Ñ€Ğ¸Ğ°Ğ»Ñ‹ |
| `comparison_heavy` | `(query) AND (vs OR solved OR ...)` | Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ |

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ:**
```python
# backend/src/services/reddit_enhanced_service.py:331-455
sort_tasks = []

# Task 1-3: Standard sorts
sort_tasks.append(("combined_relevance", self._search_with_sort(..., sort="relevance")))
sort_tasks.append(("combined_top_year", self._search_with_sort(..., sort="top", time="year")))
sort_tasks.append(("combined_new_month", self._search_with_sort(..., sort="new", time="month")))

# Task 4: AI Intent Queries
ai_queries = search_plan.get("queries", [])
for ai_q in ai_queries[:3]:
    sort_tasks.append((f"ai_intent_{i}", self._search_with_sort(full_ai_q, ...)))

# Task 5-6: High Signal + Comparison
sort_tasks.append(("high_signal_title", ...))
sort_tasks.append(("comparison_heavy", ...))

results = await asyncio.gather(*[task for _, task in sort_tasks], return_exceptions=True)
```

**ĞŸĞ»ÑÑÑ‹:**
- âœ… ĞŸĞ¾ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ‚Ğ¸Ğ¿Ğ¾Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°
- âœ… Deduplication across strategies
- âœ… Smart merging scores

### 4. Semantic Ranking Algorithm ğŸ“Š

**Context-Aware Freshness Score:**

```python
# backend/src/services/reddit_enhanced_service.py:513-565
def calculate_freshness_score(p: RedditPost) -> float:
    # Base engagement
    base_score = p.score + (p.num_comments * 2)

    # Boost Factors
    boost = 1.0

    # 1. Technical Guide Boost (Evergreen Content)
    if p.is_technical_guide:
        boost *= 1.2

    # 2. Semantic Keyword Boost (Relevance)
    if target_keywords:
        title_lower = p.title.lower()
        matches = sum(1 for k in target_keywords if k.lower() in title_lower)
        if matches > 0:
            keyword_boost = min(1.0 + (matches * 0.5), 3.0)  # Cap at x3.0
            boost *= keyword_boost

    score = base_score * boost

    # Skip Time Decay for highly relevant content
    is_highly_relevant = p.is_technical_guide or (boost > 1.5)
    if is_highly_relevant:
        return score

    # Hacker News Gravity for News/Discussions
    age_hours = (current_time - p.created_utc) / 3600
    gravity = 1.5
    return score / pow((age_hours + 2), gravity)
```

**ĞŸĞ»ÑÑÑ‹:**
- âœ… Evergreen ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ (Ğ³Ğ°Ğ¹Ğ´Ñ‹) Ğ½Ğµ penalĞ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ Ğ·Ğ° Ğ²Ğ¾Ğ·Ñ€Ğ°ÑÑ‚
- âœ… Niche Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ¼Ğ¾Ğ³ÑƒÑ‚ ĞºĞ¾Ğ½ĞºÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ viral Ğ¿Ğ¾ÑÑ‚Ğ°Ğ¼Ğ¸
- âœ… Hacker News Gravity Ğ´Ğ»Ñ news/discussions

### 5. Circuit Breaker Pattern ğŸ›¡ï¸

```
CLOSED â†’ (5 failures) â†’ OPEN â†’ (30s) â†’ HALF_OPEN â†’ (success) â†’ CLOSED
                                    â””â”€â”€ (fail) â†’ OPEN
```

**Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ:**
```python
# backend/src/services/reddit_service.py:54-137
@dataclass
class CircuitBreaker:
    failure_threshold: int = 5
    recovery_timeout: int = 30

    async def _on_failure(self, is_client_error: bool = False):
        # FIX: Client errors (4xx) don't count toward circuit breaker
        if is_client_error:
            return
        self._failure_count += 1
        if self._failure_count >= self.failure_threshold:
            self._state = CircuitState.OPEN
```

**ĞŸĞ»ÑÑÑ‹:**
- âœ… 4xx Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ½Ğµ ÑÑ‡Ğ¸Ñ‚Ğ°ÑÑ‚ÑÑ ĞºĞ°Ğº failures
- âœ… ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ
- âœ… Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ cascade failures

### 6. Synthesis Quality ğŸ“

**Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° (Inverted Pyramid):**

```python
# backend/src/services/reddit_synthesis_service.py:262-295
system_prompt = f"""...
RESPONSE STRUCTURE (Inverted Pyramid):
1. **Direct Answer / Solution:** Start immediately with the working solution or "best practice" for 2026.
2. **Technical Details:** Configs, flags, code snippets.
3. **Nuance & Debate:** If there is disagreement, state it clearly.
4. **Edge Cases:** Warnings from users (bugs, limitations).

CRITICAL ANALYSIS:
- PIVOT ALERT: If community advises against user's premise, start with ğŸš¨ COMMUNITY PIVOT
- COMPARISON TABLES: For "vs" queries, output Markdown table
- CODE VERIFICATION: Use corrected version from comments
"""
```

**Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ¸Ñ‡Ğ¸:**
- âœ… OP Verification detection: `[âœ… OP VERIFIED SOLUTION]`
- âœ… Deep comments tree (depth=3)
- âœ… Multi-language support (RU/EN)

---

## âŒ Ğ¡Ğ›ĞĞ‘Ğ«Ğ• Ğ¡Ğ¢ĞĞ ĞĞĞ«

### ğŸ”´ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ• ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ« (P0)

#### 1. `_enrich_post_content` ĞĞ• Ğ Ğ•ĞĞ›Ğ˜Ğ—ĞĞ’ĞĞ

**Ğ¤Ğ°Ğ¹Ğ»:** `backend/src/services/reddit_enhanced_service.py:692-702`

```python
async def _enrich_post_content(self, post: RedditPost) -> RedditPost:
    """Fetch full content and comments for a post.

    Note: This would require the reddit-proxy to expose get_post_details
    and get_comments tools. For now, it's a placeholder for future enhancement.
    """
    # TODO: Implement when reddit-proxy supports get_post_details
    # This would make MCP calls to fetch:
    # - Full selftext (not truncated)
    # - Top comments with content
    return post  # â† ĞŸĞ ĞĞ¡Ğ¢Ğ Ğ’ĞĞ—Ğ’Ğ ĞĞ©ĞĞ•Ğ¢ Ğ‘Ğ•Ğ— Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ™!
```

**ĞŸĞ¾ÑĞ»ĞµĞ´ÑÑ‚Ğ²Ğ¸Ñ:**
- ğŸ”´ Deep comment analysis ĞĞ• Ğ ĞĞ‘ĞĞ¢ĞĞ•Ğ¢
- ğŸ”´ Ğ¢Ğ¾Ğ¿ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¸ Ğ½Ğµ Ğ¾Ğ±Ğ¾Ğ³Ğ°Ñ‰Ğ°ÑÑ‚ÑÑ
- ğŸ”´ Ğ¢ĞµÑ€ÑĞµÑ‚ÑÑ ~50% Ñ†ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ· discussions

**ĞĞ¾:** Ğ’ Reddit Proxy (`services/reddit-proxy/src/index.ts:559-628`) enrichment Ğ Ğ•ĞĞ›Ğ˜Ğ—ĞĞ’ĞĞ:
```typescript
private async enrichResults(results: RedditSearchResult[]): Promise<RedditSearchResult[]> {
    const details = await this.mcp.executeTool<any>('get_post_details', {
      post_id: post.id,
      subreddit: post.subreddit,
      comment_limit: 50,
      comment_depth: 3
    });
    // Extract selftext and comments...
}
```

**ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°:** Backend Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ `_enrich_post_content`, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ´ĞµĞ»Ğ°ĞµÑ‚, Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑƒĞ¶Ğµ Ğ¾Ğ±Ğ¾Ğ³Ğ°Ñ‰Ñ‘Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ñ‚ Proxy.

#### 2. Credentials Ğ² Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¾Ğ¼ Ğ²Ğ¸Ğ´Ğµ

**Ğ¤Ğ°Ğ¹Ğ»:** `services/reddit-proxy/.env` (Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ¿Ğ¾Ğ¿Ğ°ÑÑ‚ÑŒ Ğ² git)

```env
REDDIT_CLIENT_ID=-SPb2C1BNI82qJVWSej41Q
REDDIT_CLIENT_SECRET=ry0Pvmuf9fEC-vgu4XFh5tDE82ehnQ
REDDIT_USERNAME=External-Way5292
REDDIT_PASSWORD=3dredditforce
```

**Ğ Ğ¸ÑĞº:**
- ğŸ”´ Ğ£Ñ‚ĞµÑ‡ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· git history
- ğŸ”´ Reddit Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ±Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ°ĞºĞºĞ°ÑƒĞ½Ñ‚
- ğŸ”´ Security audit fail

**Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ:** Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Fly.io secrets:
```bash
fly secrets set REDDIT_CLIENT_SECRET=xxx REDDIT_PASSWORD=xxx
```

#### 3. ĞĞµÑ‚ fallback ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¿Ñ€Ğ¸ Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¸ Reddit Proxy

**Ğ¤Ğ°Ğ¹Ğ»:** `backend/src/api/simplified_query_endpoint.py:1036-1044`

```python
if not reddit_complete and not reddit_task.done():
    reddit_task.cancel()
    logger.warning("Reddit pipeline timed out, proceeding without Reddit results")
    reddit_result = None  # â† ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ null, Ğ½Ğ¸ĞºĞ°ĞºĞ¸Ñ… alternatives
```

**ĞŸĞ¾ÑĞ»ĞµĞ´ÑÑ‚Ğ²Ğ¸Ğµ:**
- ğŸ”´ ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ²Ğ¸Ğ´Ğ¸Ñ‚ "Reddit: unavailable"
- ğŸ”´ ĞĞµÑ‚ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½
- ğŸ”´ ĞĞµÑ‚ retry Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸

---

### ğŸŸ  Ğ¡Ğ•Ğ Ğ¬ĞĞ—ĞĞ«Ğ• ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ« (P1)

#### 4. Query Translation â€” Ğ½ĞµÑ‚ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

**Ğ¤Ğ°Ğ¹Ğ»:** `backend/src/services/translation_service.py`

```python
async def translate_text(self, text: str, source_lang: str, target_lang: str) -> str:
    # ĞšĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ñ€Ğ°Ğ· Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Gemini Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ°
    # ĞĞ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´ÑÑ‚ÑÑ Ğ·Ğ°Ğ½Ğ¾Ğ²Ğ¾
    response = await self._call_llm(self.primary_model, messages)
```

**ĞŸĞ¾ÑĞ»ĞµĞ´ÑÑ‚Ğ²Ğ¸Ğµ:**
- ğŸŸ  Ğ›Ğ¸ÑˆĞ½Ğ¸Ğµ Ğ·Ğ°Ñ‚Ñ€Ğ°Ñ‚Ñ‹ Ğ½Ğ° API (Gemini calls)
- ğŸŸ  Latency ~500ms Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´

**Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ:** Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ LRU cache:
```python
from functools import lru_cache

@lru_cache(maxsize=100)
def _get_cached_translation(self, text_hash: str) -> Optional[str]:
    ...
```

#### 5. Magic Numbers Ğ±ĞµĞ· ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸

**Ğ—Ğ°Ñ…Ğ°Ñ€Ğ´ĞºĞ¾Ğ¶ĞµĞ½Ñ‹ Ğ² ĞºĞ¾Ğ´Ğµ:**

| Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ | Ğ¤Ğ°Ğ¹Ğ» | ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ |
|----------|------|----------|
| `Semaphore(5)` | translation_service.py:197 | Concurrency limit |
| `target_posts: int = 25` | reddit_enhanced_service.py:295 | Results limit |
| `top_posts[:10]` | reddit_enhanced_service.py:575 | Deep analysis |
| `cache.max = 100` | reddit-proxy/index.ts:689 | Cache size |
| `maxRestarts = 10` | reddit-proxy/index.ts:156 | Watchdog limit |
| `MIN_SCORE = 5` | reddit-proxy/index.ts:542 | Filter threshold |

**ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°:**
- ğŸŸ  ĞĞµĞ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ñ‚ÑĞ½Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ´ load Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ´Ğ°
- ğŸŸ  ĞĞµÑ‚ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ ÑÑ‚Ğ¸ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ

**Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ:** Ğ’Ñ‹Ğ½ĞµÑÑ‚Ğ¸ Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³:
```python
# config.py
REDDIT_TARGET_POSTS = int(os.getenv("REDDIT_TARGET_POSTS", "25"))
REDDIT_DEEP_ANALYSIS_LIMIT = int(os.getenv("REDDIT_DEEP_ANALYSIS_LIMIT", "10"))
```

#### 6. SSE Progress â€” Ğ½ĞµÑ‚ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸

**Ğ¡ĞµĞ¹Ñ‡Ğ°Ñ:**
```python
{"phase": "reddit_search", "status": "processing", "message": "Searching Reddit..."}
```

**Ğ¥Ğ¾Ñ‚ĞµĞ»Ğ¾ÑÑŒ Ğ±Ñ‹:**
```python
{
  "phase": "reddit_search",
  "status": "processing",
  "stage": "fetching_subreddit_LocalLLaMA",
  "progress": "2/6",
  "strategies_completed": ["combined_relevance", "combined_top_year"]
}
```

**ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°:**
- ğŸŸ  ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ½Ğµ Ğ²Ğ¸Ğ´Ğ¸Ñ‚ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ
- ğŸŸ  Ğ’Ñ‹Ğ³Ğ»ÑĞ´Ğ¸Ñ‚ ĞºĞ°Ğº "Ğ·Ğ°Ğ²Ğ¸ÑĞ»Ğ¾"
- ğŸŸ  ĞĞµÑ‚ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ

#### 7. ĞĞµÑ‚ rate limiting Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹

**Reddit API rate limits:**
- 60 requests/minute Ğ´Ğ»Ñ OAuth
- 10 requests/minute Ğ´Ğ»Ñ unauthenticated

**Ğ’ ĞºĞ¾Ğ´Ğµ:** ĞĞ˜Ğ§Ğ•Ğ“Ğ Ğ½Ğµ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğº Reddit Proxy

**Ğ Ğ¸ÑĞº:**
- ğŸŸ  Reddit Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ±Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ·Ğ° Ğ¿Ñ€ĞµĞ²Ñ‹ÑˆĞµĞ½Ğ¸Ğµ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ¾Ğ²
- ğŸŸ  Cascade failures Ğ¿Ñ€Ğ¸ burst traffic

**Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ:** Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ rate limiter:
```python
from aiolimiter import AsyncLimiter

# 50 requests per minute (safe margin)
reddit_rate_limiter = AsyncLimiter(50, 60)
```

---

### ğŸŸ¡ Ğ£ĞœĞ•Ğ Ğ•ĞĞĞ«Ğ• ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ« (P2)

#### 8. DEBUG Ğ»Ğ¾Ğ³Ğ¸ Ğ² production

```python
# ĞœĞ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²Ğ¾ INFO Ğ»Ğ¾Ğ³Ğ¾Ğ², ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ DEBUG:
logger.info(f"ğŸ¤– Gemini Scout Plan for '{query}': {result}")
logger.info(f"REDDIT PROXY DEBUG: Got {len(sources)} sources")
logger.info(f"SYNTHESIS DEBUG: Building context from {len(sources)} sources")
logger.info(f"[DEBUG] get_post_details for {post.id} returned keys: ...")
```

**ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°:**
- ğŸŸ¡ Ğ—Ğ°ÑĞ¾Ñ€ÑĞµÑ‚ Ğ»Ğ¾Ğ³Ğ¸
- ğŸŸ¡ ĞŸĞ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ sensitive data Ğ² Ğ»Ğ¾Ğ³Ğ°Ñ…

#### 9. Frontend markdown â€” Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ğ°Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ°

**ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚:**
- Headers (## ### ####)
- **bold**, *italic*
- `code` Ğ¸ ```code blocks```

**ĞĞ• Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚:**
- Tables (Ñ…Ğ¾Ñ‚Ñ synthesis Ğ¸Ñ… Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚!)
- Task lists
- Footnotes

**ĞŸĞ¾ÑĞ»ĞµĞ´ÑÑ‚Ğ²Ğ¸Ğµ:**
- ğŸŸ¡ Comparison tables Ñ€ĞµĞ½Ğ´ĞµÑ€ÑÑ‚ÑÑ ĞºĞ°Ğº plain text
- ğŸŸ¡ ĞŸĞ»Ğ¾Ñ…Ğ¾Ğ¹ UX Ğ´Ğ»Ñ vs-Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²

#### 10. ĞĞµÑ‚ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… Ñ‚ĞµÑÑ‚Ğ¾Ğ²

**Ğ•ÑÑ‚ÑŒ:**
```bash
backend/test_reddit_api.py           # Unit test API
backend/test_reddit_comprehensive.py # Manual test script
backend/test_reddit_api2.py          # Another manual test
```

**ĞĞ•Ğ¢:**
- âŒ Frontend â†’ Backend â†’ Reddit Proxy end-to-end
- âŒ SSE streaming tests
- âŒ Error scenario tests
- âŒ Performance tests

---

## ğŸ—ï¸ ĞĞ Ğ¥Ğ˜Ğ¢Ğ•ĞšĞ¢Ğ£Ğ ĞĞ«Ğ• Ğ’ĞĞŸĞ ĞĞ¡Ğ«

### 1. Ğ”ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

```python
# reddit_service.py
@dataclass
class RedditSource:
    title: str
    url: str
    score: int
    comments_count: int  # â† comments_count

# reddit_enhanced_service.py
@dataclass
class RedditPost:
    id: str
    title: str
    num_comments: int  # â† num_comments (Ğ´Ñ€ÑƒĞ³Ğ¾Ğµ Ğ¸Ğ¼Ñ!)
```

**ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°:** Different naming conventions = confusion

### 2. Ğ”Ğ²Ğ° ÑƒÑ€Ğ¾Ğ²Ğ½Ñ Circuit Breaker

```
RedditEnhancedService._circuit_breaker (instance)
    â†“
RedditService._circuit_breaker (inherited)
```

**Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ:** ĞĞ±Ğ° Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹? ĞšĞ°Ğº Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²ÑƒÑÑ‚?

### 3. Proxy Timeout vs Pipeline Timeout

```python
# reddit_enhanced_service.py
DEFAULT_TIMEOUT = 30.0  # HTTP timeout

# simplified_query_endpoint.py
reddit_timeout = 120.0  # Pipeline timeout
```

**Ğ Ğ°ÑÑ‡Ñ‘Ñ‚:** 4 HTTP Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ã— 30s = 120s â€” Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ½Ğ° Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ğµ!

**Ğ Ğ¸ÑĞº:** ĞŸÑ€Ğ¸ Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ğ¾Ğ¹ ÑĞµÑ‚Ğ¸ pipeline timeout Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑÑ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ½ÑŒÑˆĞµ

---

## ğŸ“Š Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ¾Ñ†ĞµĞ½ĞºĞ¸

| ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ | ĞÑ†ĞµĞ½ĞºĞ° | Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° |
|-----------|--------|------------------|
| **Architecture** | â­â­â­â­ | Sidecar Ñ…Ğ¾Ñ€Ğ¾Ñˆ, Ğ½Ğ¾ single point of failure |
| **AI Scout** | â­â­â­â­â­ | ĞÑ‚Ğ»Ğ¸Ñ‡Ğ½Ğ°Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ intent-based Ğ¿Ğ¾Ğ¸ÑĞºĞ° |
| **Search Strategies** | â­â­â­â­ | Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞµĞµ Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ, Ğ½Ğ¾ Ğ½ĞµÑ‚ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ |
| **Semantic Ranking** | â­â­â­â­â­ | ĞŸÑ€Ğ¾Ğ´ÑƒĞ¼Ğ°Ğ½Ğ½Ñ‹Ğ¹ algorithm Ñ context-awareness |
| **Circuit Breaker** | â­â­â­â­ | Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚, Ğ½Ğ¾ Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ |
| **Deep Analysis** | â­ | **ĞĞ• Ğ ĞĞ‘ĞĞ¢ĞĞ•Ğ¢** â€” TODO placeholder |
| **Translation** | â­â­â­ | ĞĞµÑ‚ ĞºÑÑˆĞ°, magic numbers |
| **Error Handling** | â­â­â­ | Generic, Ğ½Ğµ Reddit-specific |
| **SSE Progress** | â­â­ | ĞĞµÑ‚ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, user confusion |
| **Testing** | â­â­ | ĞĞµÑ‚ integration tests |
| **Security** | â­â­ | Credentials exposure, no rate limiting |
| **Frontend** | â­â­â­â­ | Good UX, limited markdown |

---

## ğŸ¯ ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ½Ñ‹Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸

### P0 â€” ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¾ (ÑĞ´ĞµĞ»Ğ°Ñ‚ÑŒ ÑĞµĞ¹Ñ‡Ğ°Ñ)

| # | Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° | Ğ¤Ğ°Ğ¹Ğ» | ĞÑ†ĞµĞ½ĞºĞ° Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ |
|---|--------|------|----------------|
| 1 | Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ `_enrich_post_content` | reddit_enhanced_service.py | 2h |
| 2 | Ğ£Ğ´Ğ°Ğ»Ğ¸Ñ‚ÑŒ credentials Ğ¸Ğ· .env â†’ Fly.io secrets | .env, fly.toml | 0.5h |
| 3 | Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ rate limiting | reddit_enhanced_service.py | 1h |

### P1 â€” Ğ’Ğ°Ğ¶Ğ½Ğ¾ (ÑÑ‚Ğ° Ğ½ĞµĞ´ĞµĞ»Ñ)

| # | Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° | Ğ¤Ğ°Ğ¹Ğ» | ĞÑ†ĞµĞ½ĞºĞ° Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ |
|---|--------|------|----------------|
| 4 | ĞšÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¾Ğ² | translation_service.py | 1h |
| 5 | ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ñ‹Ğµ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ â†’ env vars | config.py | 1h |
| 6 | Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ SSE progress | simplified_query_endpoint.py | 2h |

### P2 â€” Ğ£Ğ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ (ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑĞ¿Ñ€Ğ¸Ğ½Ñ‚)

| # | Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° | Ğ¤Ğ°Ğ¹Ğ» | ĞÑ†ĞµĞ½ĞºĞ° Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ |
|---|--------|------|----------------|
| 7 | Integration tests | tests/ | 4h |
| 8 | Metrics & Monitoring | monitoring/ | 2h |
| 9 | Better markdown support (tables) | CommunityInsightsSection.tsx | 2h |
| 10 | Fallback strategy (cached results) | simplified_query_endpoint.py | 2h |

---

## ğŸ“ˆ ĞŸĞ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ» ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ğ¹

ĞŸĞ¾ÑĞ»Ğµ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ P0 Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼:
- ĞÑ†ĞµĞ½ĞºĞ° Ğ¿Ğ¾Ğ´Ğ½Ğ¸Ğ¼ĞµÑ‚ÑÑ Ñ â­â­â­ Ğ´Ğ¾ â­â­â­â­
- Deep analysis Ğ½Ğ°Ñ‡Ğ½Ñ‘Ñ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ
- Security Ñ€Ğ¸ÑĞºĞ¸ ÑƒÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ñ‹

ĞŸĞ¾ÑĞ»Ğµ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ P0 + P1:
- ĞÑ†ĞµĞ½ĞºĞ° Ğ¿Ğ¾Ğ´Ğ½Ğ¸Ğ¼ĞµÑ‚ÑÑ Ğ´Ğ¾ â­â­â­â­â­
- User experience Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑÑ
- Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑÑ‚Ğ°Ğ½ĞµÑ‚ production-ready

---

## ğŸ”— Ğ¡Ğ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹

- Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ: `docs/pipeline-architecture.md`
- Backend docs: `backend/CLAUDE.md`
- Frontend docs: `frontend/CLAUDE.md`
- Proxy README: `services/reddit-proxy/README.md`

---

*ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½ Claude (GLM-5) Ğ² Ñ€Ğ°Ğ¼ĞºĞ°Ñ… code review ÑĞµÑÑĞ¸Ğ¸.*
